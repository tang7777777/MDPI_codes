{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c697ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\envs\\ta\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72de0ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration SetFit___subj-848ec40cb3887b72\n",
      "Reusing dataset json (C:\\Users\\DELL\\.cache\\huggingface\\datasets\\json\\SetFit___subj-848ec40cb3887b72\\0.0.0\\c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 83.19it/s]\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\DELL\\.cache\\huggingface\\datasets\\json\\SetFit___subj-848ec40cb3887b72\\0.0.0\\c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\\cache-80b8e4129e527f71.arrow\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "dataset = load_dataset(\"SetFit/subj\")\n",
    "dataset = dataset.remove_columns(\"label_text\")\n",
    "dataset = dataset['train'].shuffle(seed=42).select([i for i in list(range(6000))])\n",
    "train_ds = Dataset.from_dict(dataset[0:5000])\n",
    "validation_ds = Dataset.from_dict(dataset[5000:5500])\n",
    "test_ds = Dataset.from_dict(dataset[5500:6000])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad687680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_ds)\n",
    "display(validation_ds)\n",
    "display(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95403ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': [\"on this morning , johnny wakes to his mother 's accusations that he has botched a simple scam , leaving them without enough money to payoff their inside man .\",\n",
       "  \"despite a quieter middle section , involving aragorn 's dreams of arwen , this is even better than the fellowship . there are scenes of cinematic perfection that steal your heart away .\",\n",
       "  '[ kidd ] can write dialogue , work skillfully with actors , and he has a pretty good handle on urban loneliness of the knowing , virulent new york city variety .',\n",
       "  'abandoned and filled with a mysterious past , holy angel school for girls is about to reveal its secrets of betrayal , jealousy , and vengeance .',\n",
       "  \"the romantic triangle leads to a surprising conclusion as the young man 's secret motive has explosive consequences .\"],\n",
       " 'label': [0, 1, 1, 0, 0]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_ds[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72ec0ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': [\"he has all the kit but none of the skill , and he 's a laughing stock at school .\",\n",
       "  'although disney follows its standard formula in this animated adventure , it feels more forced than usual .',\n",
       "  'several uninteresting , unlikeable people do bad things to and with each other in `` unfaithful . `` why anyone who is not a character in this movie should care is beyond me .',\n",
       "  \"'you 'll laugh for not quite and hour and a half , but come out feeling strangely unsatisfied . you 'll feel like you ate a reeses without the peanut butter . . . '\",\n",
       "  'a forceful drama of an alienated executive who re-invents himself .'],\n",
       " 'label': [0, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(validation_ds[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3af3c42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['he can remember nothing and begins to try to rebuild his memory based on clues such as the swiss bank account , the number of which , is implanted in his hip .',\n",
       "  'leaving her successful career and las vegas forever in order to build her family in a healthy environment was since long prevented by katherine hiller ( barbara carrera ) , her discoverer and business manager .',\n",
       "  \"a film worthy of comparison to truffaut 's best cinematic poems .\",\n",
       "  'in the end there is one word that best describes this film : honest .',\n",
       "  'angry and confused teen runaways come and go at the shelter , as steve learns he is not alone in his predicament and that the streets offer a harsh reality .'],\n",
       " 'label': [0, 0, 1, 1, 0]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(test_ds[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6644348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5267bc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function <lambda> at 0x000001B7F2A00280> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 29.26ba/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 55.74ba/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 52.88ba/s]\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#defining model:\n",
    "from transformers import (AutoTokenizer, \n",
    "                          AutoModelForSequenceClassification, \n",
    "                          Trainer, EarlyStoppingCallback,\n",
    "                          TrainingArguments)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "tokenize_func = lambda sentences: tokenizer(sentences['text'], \n",
    "                                            padding='max_length', truncation=True, max_length = 100)\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = train_ds.map(tokenize_func, batched=True)\n",
    "val_dataset = validation_ds.map(tokenize_func, batched=True)\n",
    "test_dataset = test_ds.map(tokenize_func, batched=True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d28a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    " \n",
    "def compute_metrics(eval_pred):\n",
    "   load_accuracy = load_metric(\"accuracy\")\n",
    "   load_f1 = load_metric(\"f1\")\n",
    "  \n",
    "   logits, labels = eval_pred\n",
    "   predictions = np.argmax(logits, axis=-1)\n",
    "   accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "   f1 = load_f1.compute(predictions=predictions, references=labels, average='macro')[\"f1\"]\n",
    "   return {\"accuracy\": accuracy, \"f1\": f1}\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=r'C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model',          # output directory\n",
    "    num_train_epochs=20,              # total number of training epochs\n",
    "    per_device_train_batch_size=32,  # batch size per device during training\n",
    "    per_device_eval_batch_size=32,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.1,               # strength of weight decay\n",
    "    \n",
    "    logging_dir=r'C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\logs\\original_model',            # directory for storing logs\n",
    "    save_total_limit = 1,\n",
    "    load_best_model_at_end=True,\n",
    "    #metric_for_best_model='f1',\n",
    "    evaluation_strategy='epoch',\n",
    "    logging_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=2e-5,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=training_args, \n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07f4e16e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running training *****\n",
      "  Num examples = 5000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 1560\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='546' max='1560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 546/1560 04:36 < 08:36, 1.96 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.685400</td>\n",
       "      <td>0.622450</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.888447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.213245</td>\n",
       "      <td>0.926000</td>\n",
       "      <td>0.925714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.168100</td>\n",
       "      <td>0.170546</td>\n",
       "      <td>0.934000</td>\n",
       "      <td>0.933637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>0.145002</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.951870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.205265</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.929997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.038100</td>\n",
       "      <td>0.199965</td>\n",
       "      <td>0.946000</td>\n",
       "      <td>0.945989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>0.302351</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.929986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Using the latest cached version of the module from C:\\Users\\DELL\\.cache\\huggingface\\modules\\datasets_modules\\metrics\\accuracy\\3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Sat Aug 13 21:10:49 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Saving model checkpoint to C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-78\n",
      "Configuration saved in C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-78\\config.json\n",
      "Model weights saved in C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-78\\pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Using the latest cached version of the module from C:\\Users\\DELL\\.cache\\huggingface\\modules\\datasets_modules\\metrics\\accuracy\\3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Sat Aug 13 21:10:49 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Saving model checkpoint to C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-156\n",
      "Configuration saved in C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-156\\config.json\n",
      "Model weights saved in C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-156\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-78] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-234\n",
      "Configuration saved in C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-234\\config.json\n",
      "Model weights saved in C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-234\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-156] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Using the latest cached version of the module from C:\\Users\\DELL\\.cache\\huggingface\\modules\\datasets_modules\\metrics\\f1\\6a64529c5745513ceb230ce9696115dcad6ae0fedad9946e3f2f723a65a0cd53 (last modified on Sat Aug 13 21:10:53 2022) since it couldn't be found locally at f1, or remotely on the Hugging Face Hub.\n",
      "Saving model checkpoint to C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-312\n",
      "Configuration saved in C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-312\\config.json\n",
      "Model weights saved in C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-312\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-234] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-390\n",
      "Configuration saved in C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-390\\config.json\n",
      "Model weights saved in C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-390\\pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Using the latest cached version of the module from C:\\Users\\DELL\\.cache\\huggingface\\modules\\datasets_modules\\metrics\\accuracy\\3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Sat Aug 13 21:10:49 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Saving model checkpoint to C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-468\n",
      "Configuration saved in C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-468\\config.json\n",
      "Model weights saved in C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-468\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-390] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-546\n",
      "Configuration saved in C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-546\\config.json\n",
      "Model weights saved in C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-546\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-468] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\checkpoint-312 (score: 0.14500215649604797).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=546, training_loss=0.21253916108127915, metrics={'train_runtime': 280.0657, 'train_samples_per_second': 357.059, 'train_steps_per_second': 5.57, 'total_flos': 905538858000000.0, 'train_loss': 0.21253916108127915, 'epoch': 6.99})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training:\n",
    "trainer.train(ignore_keys_for_eval=['last_hidden_state', 'hidden_states', 'attentions'])\n",
    "# We are going to get multiple loss values on each training step here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be8a1b7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\n",
      "Configuration saved in C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\config.json\n",
      "Model weights saved in C:\\Users\\DELL\\Text_Augmentation\\subj_dataset_3runs\\models\\original_model\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "#save model:\n",
    "trainer.save_state()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4f5350e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\DELL\\.cache\\huggingface\\modules\\datasets_modules\\metrics\\f1\\6a64529c5745513ceb230ce9696115dcad6ae0fedad9946e3f2f723a65a0cd53 (last modified on Sat Aug 13 21:10:53 2022) since it couldn't be found locally at f1, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.1209598183631897,\n",
       " 'eval_accuracy': 0.958,\n",
       " 'eval_f1': 0.9579715887940248,\n",
       " 'eval_runtime': 33.3534,\n",
       " 'eval_samples_per_second': 14.991,\n",
       " 'eval_steps_per_second': 0.48,\n",
       " 'epoch': 6.99}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate:\n",
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc58749f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ta",
   "language": "python",
   "name": "ta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
