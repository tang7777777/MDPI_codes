{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c697ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\envs\\ta\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72de0ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (C:\\Users\\DELL\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 53.70it/s]\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\DELL\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548\\cache-dd0ff9596fea92b0.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\DELL\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548\\cache-12f3c4e4bf422cce.arrow\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "dataset = load_dataset('ag_news')\n",
    "train_ds = dataset['train'].shuffle(seed=42).select([i for i in list(range(5000))])\n",
    "validation_test_ds = dataset['test'].shuffle(seed=42).select([i for i in list(range(1000))])\n",
    "validation_ds = Dataset.from_dict(validation_test_ds[0:500])\n",
    "test_ds = Dataset.from_dict(validation_test_ds[500:1000])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95403ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Bangladesh paralysed by strikes Opposition activists have brought many towns and cities in Bangladesh to a halt, the day after 18 people died in explosions at a political rally.',\n",
       "  'Desiring Stability Redskins coach Joe Gibbs expects few major personnel changes in the offseason and wants to instill a culture of stability in Washington.',\n",
       "  'Will Putin #39;s Power Play Make Russia Safer? Outwardly, Russia has not changed since the barrage of terrorist attacks that culminated in the school massacre in Beslan on Sept.',\n",
       "  'U2 pitches for Apple New iTunes ads airing during baseball games Tuesday will feature the advertising-shy Irish rockers.',\n",
       "  'S African TV in beheading blunder Public broadcaster SABC apologises after news bulletin shows footage of American beheaded in Iraq.'],\n",
       " 'label': [0, 1, 0, 3, 0]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_ds[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72ec0ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Indian board plans own telecast of Australia series The Indian cricket board said on Wednesday it was making arrangements on its own to broadcast next month #39;s test series against Australia, which is under threat because of a raging TV rights dispute.',\n",
       "  'Stocks Higher on Drop in Jobless Claims A sharp drop in initial unemployment claims and bullish forecasts from Nokia and Texas Instruments sent stocks slightly higher in early trading Thursday.',\n",
       "  'Nuggets 112, Raptors 106 Carmelo Anthony scored 30 points and Kenyon Martin added 24 points and 16 rebounds, helping the Denver Nuggets hold off the Toronto Raptors 112-106 Wednesday night.',\n",
       "  'Stocks Higher on Drop in Jobless Claims A sharp drop in initial unemployment claims and bullish forecasts from Nokia and Texas Instruments sent stocks higher in early trading Thursday.',\n",
       "  'REVIEW: \\'Half-Life 2\\' a Tech Masterpiece (AP) AP - It\\'s been six years since Valve Corp. perfected the first-person shooter with \"Half-Life.\" Video games have come a long way since, with better graphics and more options than ever. Still, relatively few games have mustered this one\\'s memorable characters and original science fiction story.'],\n",
       " 'label': [1, 2, 1, 2, 3]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(validation_ds[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af3c42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['A Sneak Peek at Trillian 3.0 Instant Messaging The popular IM consolidation service adds audio and video chat.',\n",
       "  'New Technology Powers Fuel Cells A new fuel cell for notebook PCs, more compact and powerful than competing technologies, could be on the market in early 2006 at a price of around \\\\$90, its Japanese inventors claim.',\n",
       "  \"Court rules against state Web-blocking law A Pennsylvania law requiring Internet service providers to block Web sites deemed by the state's prosecuting attorneys to be child pornography has been reversed by a U.S. federal court on free-speech grounds.\",\n",
       "  'Braves, Smoltz agree to new deal Atlanta, GA (Sports Network) - The Atlanta Braves announced Thursday that the team has come to terms with longtime pitcher John Smoltz to a new two-year contract with a club option for the 2007 season.',\n",
       "  \"US Supreme Court asked to rule on homosexuals' right to adopt children (AFP) AFP - The American Civil Liberties Union, the leading US civil rights group, petitioned the US Supreme Court to rule on the right of homosexuals to adopt children.\"],\n",
       " 'label': [3, 3, 3, 1, 0]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(test_ds[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6644348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5267bc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function <lambda> at 0x0000020C6C1D9D30> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Loading cached processed dataset at C:\\Users\\DELL\\.cache\\huggingface\\datasets\\ag_news\\default\\0.0.0\\bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548\\cache-1c80317fa3b1799d.arrow\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 29.49ba/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 34.57ba/s]\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#defining model:\n",
    "from transformers import (AutoTokenizer, \n",
    "                          AutoModelForSequenceClassification, \n",
    "                          Trainer, EarlyStoppingCallback,\n",
    "                          TrainingArguments)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "tokenize_func = lambda sentences: tokenizer(sentences['text'], \n",
    "                                            padding='max_length', truncation=True, max_length = 200)\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = train_ds.map(tokenize_func, batched=True)\n",
    "val_dataset = validation_ds.map(tokenize_func, batched=True)\n",
    "test_dataset = test_ds.map(tokenize_func, batched=True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d28a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    " \n",
    "def compute_metrics(eval_pred):\n",
    "   load_accuracy = load_metric(\"accuracy\")\n",
    "   load_f1 = load_metric(\"f1\")\n",
    "  \n",
    "   logits, labels = eval_pred\n",
    "   predictions = np.argmax(logits, axis=-1)\n",
    "   accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "   f1 = load_f1.compute(predictions=predictions, references=labels, average='macro')[\"f1\"]\n",
    "   return {\"accuracy\": accuracy, \"f1\": f1}\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=r'C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model',          # output directory\n",
    "    num_train_epochs=20,              # total number of training epochs\n",
    "    per_device_train_batch_size=32,  # batch size per device during training\n",
    "    per_device_eval_batch_size=32,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.1,               # strength of weight decay\n",
    "    \n",
    "    logging_dir=r'C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\logs\\original_model',            # directory for storing logs\n",
    "    save_total_limit = 1,\n",
    "    load_best_model_at_end=True,\n",
    "    #metric_for_best_model='f1',\n",
    "    evaluation_strategy='epoch',\n",
    "    logging_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=2e-5,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=training_args, \n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07f4e16e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running training *****\n",
      "  Num examples = 3000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 940\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='564' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [564/940 16:04 < 10:45, 0.58 it/s, Epoch 12/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.390400</td>\n",
       "      <td>1.368018</td>\n",
       "      <td>0.318000</td>\n",
       "      <td>0.220496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.324700</td>\n",
       "      <td>1.221997</td>\n",
       "      <td>0.788000</td>\n",
       "      <td>0.792612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.010200</td>\n",
       "      <td>0.775559</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.809491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.595200</td>\n",
       "      <td>0.497714</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.864526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.390800</td>\n",
       "      <td>0.405891</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.878727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.311600</td>\n",
       "      <td>0.391457</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.880664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>0.388851</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.892059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.206800</td>\n",
       "      <td>0.379693</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.886861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.157400</td>\n",
       "      <td>0.331542</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.893797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.383789</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.894066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.077500</td>\n",
       "      <td>0.406441</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.883586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.416146</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.887460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Using the latest cached version of the module from C:\\Users\\DELL\\.cache\\huggingface\\modules\\datasets_modules\\metrics\\f1\\6a64529c5745513ceb230ce9696115dcad6ae0fedad9946e3f2f723a65a0cd53 (last modified on Sat Aug 13 21:10:53 2022) since it couldn't be found locally at f1, or remotely on the Hugging Face Hub.\n",
      "Saving model checkpoint to C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-47\n",
      "Configuration saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-47\\config.json\n",
      "Model weights saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-47\\pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-94\n",
      "Configuration saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-94\\config.json\n",
      "Model weights saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-94\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-47] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-141\n",
      "Configuration saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-141\\config.json\n",
      "Model weights saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-141\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-94] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Using the latest cached version of the module from C:\\Users\\DELL\\.cache\\huggingface\\modules\\datasets_modules\\metrics\\accuracy\\3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Sat Aug 13 21:10:49 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Saving model checkpoint to C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-188\n",
      "Configuration saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-188\\config.json\n",
      "Model weights saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-188\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-141] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-235\n",
      "Configuration saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-235\\config.json\n",
      "Model weights saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-235\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-188] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Using the latest cached version of the module from C:\\Users\\DELL\\.cache\\huggingface\\modules\\datasets_modules\\metrics\\accuracy\\3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Sat Aug 13 21:10:49 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from C:\\Users\\DELL\\.cache\\huggingface\\modules\\datasets_modules\\metrics\\f1\\6a64529c5745513ceb230ce9696115dcad6ae0fedad9946e3f2f723a65a0cd53 (last modified on Sat Aug 13 21:10:53 2022) since it couldn't be found locally at f1, or remotely on the Hugging Face Hub.\n",
      "Saving model checkpoint to C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-282\n",
      "Configuration saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-282\\config.json\n",
      "Model weights saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-282\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-235] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Using the latest cached version of the module from C:\\Users\\DELL\\.cache\\huggingface\\modules\\datasets_modules\\metrics\\accuracy\\3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Sat Aug 13 21:10:49 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n",
      "Saving model checkpoint to C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-329\n",
      "Configuration saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-329\\config.json\n",
      "Model weights saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-329\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-282] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Using the latest cached version of the module from C:\\Users\\DELL\\.cache\\huggingface\\modules\\datasets_modules\\metrics\\f1\\6a64529c5745513ceb230ce9696115dcad6ae0fedad9946e3f2f723a65a0cd53 (last modified on Sat Aug 13 21:10:53 2022) since it couldn't be found locally at f1, or remotely on the Hugging Face Hub.\n",
      "Saving model checkpoint to C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-376\n",
      "Configuration saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-376\\config.json\n",
      "Model weights saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-376\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-329] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Using the latest cached version of the module from C:\\Users\\DELL\\.cache\\huggingface\\modules\\datasets_modules\\metrics\\accuracy\\3e9ee15abf476145152fe4e9a9c1463ff95d3d65cdc555be9cfe061bdaeb1a14 (last modified on Sat Aug 13 21:10:49 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\DELL\\.cache\\huggingface\\modules\\datasets_modules\\metrics\\f1\\6a64529c5745513ceb230ce9696115dcad6ae0fedad9946e3f2f723a65a0cd53 (last modified on Sat Aug 13 21:10:53 2022) since it couldn't be found locally at f1, or remotely on the Hugging Face Hub.\n",
      "Saving model checkpoint to C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-423\n",
      "Configuration saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-423\\config.json\n",
      "Model weights saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-423\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-376] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-470\n",
      "Configuration saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-470\\config.json\n",
      "Model weights saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-470\\pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Using the latest cached version of the module from C:\\Users\\DELL\\.cache\\huggingface\\modules\\datasets_modules\\metrics\\f1\\6a64529c5745513ceb230ce9696115dcad6ae0fedad9946e3f2f723a65a0cd53 (last modified on Sat Aug 13 21:10:53 2022) since it couldn't be found locally at f1, or remotely on the Hugging Face Hub.\n",
      "Saving model checkpoint to C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-517\n",
      "Configuration saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-517\\config.json\n",
      "Model weights saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-517\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-470] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n",
      "Using the latest cached version of the module from C:\\Users\\DELL\\.cache\\huggingface\\modules\\datasets_modules\\metrics\\f1\\6a64529c5745513ceb230ce9696115dcad6ae0fedad9946e3f2f723a65a0cd53 (last modified on Sat Aug 13 21:10:53 2022) since it couldn't be found locally at f1, or remotely on the Hugging Face Hub.\n",
      "Saving model checkpoint to C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-564\n",
      "Configuration saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-564\\config.json\n",
      "Model weights saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-564\\pytorch_model.bin\n",
      "Deleting older checkpoint [C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-517] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\checkpoint-423 (score: 0.33154210448265076).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=564, training_loss=0.48898827141903817, metrics={'train_runtime': 968.403, 'train_samples_per_second': 61.958, 'train_steps_per_second': 0.971, 'total_flos': 4768996442112000.0, 'train_loss': 0.48898827141903817, 'epoch': 12.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training:\n",
    "trainer.train(ignore_keys_for_eval=['last_hidden_state', 'hidden_states', 'attentions'])\n",
    "# We are going to get multiple loss values on each training step here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be8a1b7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\n",
      "Configuration saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\config.json\n",
      "Model weights saved in C:\\Users\\DELL\\Text_Augmentation\\ag_news_dataset_3runs\\models\\original_model\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "#save model:\n",
    "trainer.save_state()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4f5350e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 500\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3214978575706482,\n",
       " 'eval_accuracy': 0.9,\n",
       " 'eval_f1': 0.8979683758897417,\n",
       " 'eval_runtime': 37.2709,\n",
       " 'eval_samples_per_second': 13.415,\n",
       " 'eval_steps_per_second': 0.429,\n",
       " 'epoch': 12.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate:\n",
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc58749f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ta",
   "language": "python",
   "name": "ta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
